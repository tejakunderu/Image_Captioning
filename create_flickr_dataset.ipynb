{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cPickle\n",
    "import skimage\n",
    "import cv2\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_path = './flickr30k/results_20130124.token'\n",
    "flickr_image_path = './flickr30k-images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg#0</td>\n",
       "      <td>Two young guys with shaggy hair look at their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg#1</td>\n",
       "      <td>Two young , White males are outside near many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg#2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg#3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg#4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                img                                            caption\n",
       "0  1000092795.jpg#0  Two young guys with shaggy hair look at their ...\n",
       "1  1000092795.jpg#1  Two young , White males are outside near many ...\n",
       "2  1000092795.jpg#2   Two men in green shirts are standing in a yard .\n",
       "3  1000092795.jpg#3       A man in a blue shirt standing in a garden .\n",
       "4  1000092795.jpg#4            Two friends enjoy time spent together ."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.read_table(caption_path, sep='\\t', header=None, names=['img', 'caption'])\n",
    "captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>caption</th>\n",
       "      <th>img_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two young guys with shaggy hair look at their ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two young , White males are outside near many ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img                                            caption img_num\n",
       "0  1000092795.jpg  Two young guys with shaggy hair look at their ...       0\n",
       "1  1000092795.jpg  Two young , White males are outside near many ...       1\n",
       "2  1000092795.jpg   Two men in green shirts are standing in a yard .       2\n",
       "3  1000092795.jpg       A man in a blue shirt standing in a garden .       3\n",
       "4  1000092795.jpg            Two friends enjoy time spent together .       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions['img'], captions['img_num'] = captions['img'].str.split('#',1).str\n",
    "captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>caption</th>\n",
       "      <th>img_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./flickr30k-images/1000092795.jpg</td>\n",
       "      <td>Two young guys with shaggy hair look at their ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./flickr30k-images/1000092795.jpg</td>\n",
       "      <td>Two young , White males are outside near many ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./flickr30k-images/1000092795.jpg</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./flickr30k-images/1000092795.jpg</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./flickr30k-images/1000092795.jpg</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 img  \\\n",
       "0  ./flickr30k-images/1000092795.jpg   \n",
       "1  ./flickr30k-images/1000092795.jpg   \n",
       "2  ./flickr30k-images/1000092795.jpg   \n",
       "3  ./flickr30k-images/1000092795.jpg   \n",
       "4  ./flickr30k-images/1000092795.jpg   \n",
       "\n",
       "                                             caption img_num  \n",
       "0  Two young guys with shaggy hair look at their ...       0  \n",
       "1  Two young , White males are outside near many ...       1  \n",
       "2   Two men in green shirts are standing in a yard .       2  \n",
       "3       A man in a blue shirt standing in a garden .       3  \n",
       "4            Two friends enjoy time spent together .       4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions['img'] = flickr_image_path + captions['img'].astype(str)\n",
    "captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = captions['img'].values\n",
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(x, ht, wd):\n",
    "    \n",
    "    img = skimage.io.imread(x)\n",
    "    img = skimage.img_as_float(img).astype(np.float32)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.tile(img[:,:,None], 3)\n",
    "    elif len(img.shape) == 4:\n",
    "        img = img[:,:,:,0]\n",
    "\n",
    "    img_ht, img_wd, img_ch = img.shape\n",
    "    if img_wd == img_ht:\n",
    "        resized_img = cv2.resize(img, (ht, wd))\n",
    "\n",
    "    elif img_ht < img_wd:\n",
    "        resized_img = cv2.resize(img, (int(img_wd * float(ht)/ht), wd))\n",
    "        cropping_length = int((resized_img.shape[1] - ht) / 2)\n",
    "        resized_img = resized_img[:,cropping_length:resized_img.shape[1] - cropping_length]\n",
    "\n",
    "    else:\n",
    "        resized_img = cv2.resize(img, (ht, int(img_ht * float(wd) / wd)))\n",
    "        cropping_length = int((resized_img.shape[0] - wd) / 2)\n",
    "        resized_img = resized_img[cropping_length:resized_img.shape[0] - cropping_length,:]\n",
    "\n",
    "    return cv2.resize(resized_img, (ht, wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_cnn_model = 'VGG_ILSVRC_19_layers.caffemodel'\n",
    "vgg19_deploy = 'VGG_ILSVRC_19_layers_deploy.prototxt'\n",
    "mean = 'ilsvrc_2012_mean.npy'\n",
    "\n",
    "net = caffe.Net(vgg19_deploy, vgg19_cnn_model, caffe.TEST)\n",
    "\n",
    "transformer = caffe.io.Transformer({'data':net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data', np.load(mean).mean(1).mean(1))\n",
    "transformer.set_raw_scale('data', 255)\n",
    "transformer.set_channel_swap('data', (2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = CNN(model=vgg19_cnn_model, deploy=vgg_deploy, width=224, height=224)\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "batch_size = 10 # VGG_ILSVRC_19_layers_deploy.prototxt has batch size = 10\n",
    "layer_sizes = [4096]\n",
    "layers='fc7'\n",
    "\n",
    "if not os.path.exists('./features.npy'):\n",
    "\n",
    "    i = len(image_list) + batch_size\n",
    "    features = np.zeros([len(image_list)] + layer_sizes)\n",
    "\n",
    "    for start, end in zip(range(0, i, batch_size), range(batch_size, i, batch_size)):\n",
    "        image_batch_file = image_list[start:end]\n",
    "        image_batch = np.array(map(lambda x: resize_img(x, width, height), image_batch_file))\n",
    "        caffe_in = np.zeros(np.array(image_batch.shape)[[0,3,1,2]], dtype=np.float32)\n",
    "        for idx, inside in enumerate(image_batch):\n",
    "            caffe_in[idx] = transformer.preprocess('data', inside)\n",
    "        out = net.forward_all(blobs=[layers], **{'data':caffe_in})\n",
    "        feats = out[layers]\n",
    "        features[start:end] = feats\n",
    "\n",
    "    np.save('./features.npy', features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
